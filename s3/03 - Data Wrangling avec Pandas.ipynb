{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling avec Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une grande partie du métier de Data Scientist, consiste à nétoyer, arranger des données afin de les exploiter. \n",
    "\n",
    "Maîtriser cette partie du processus est essentiel : les données que vous aurait l'occasion d'analyser seront rarement sous la forme d'un DataFrame propre.\n",
    "    \n",
    "A la fin de cette partie, vous saurez :\n",
    "    \n",
    "- Fusionner deux DataFrame avec la méthode **merge**\n",
    "- Retravailler, faire pivoter deux datasets avec les méthodes **stack** et **pivot**\n",
    "- Remplacer des valeurs à partir d'un dictionnaire grâce à la méthode **map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusionner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusionner consiste à rassembler les lignes de deux DataFrames en utilisant une clé commune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons deux sets de données. \n",
    "\n",
    "Le premier contient des id de commandes. Le second la correspondance entre id client et nom et prenoms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dict = {'customer_id':['3','2','1','4'],\n",
    "          'order_value':[40,35,50,45],\n",
    "          'order_id':['4001','4002','4003','4004']}\n",
    "\n",
    "customers_dict = {'customer_id':['1','2','3','4','5'],\n",
    "                  'nom':['CAMPAN','DOE','MUSK','JOBS','FRANKO'],\n",
    "                  'prenom':['Bernard','John','Elon','Steve','James']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons créer deux DataFrames pour chacun de ces dictionnaires, soit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.DataFrame(orders_dict,\n",
    "                       columns=['customer_id','order_value'],\n",
    "                       index = orders_dict['order_id'])\n",
    "\n",
    "customers = pd.DataFrame(customers_dict,\n",
    "                         index = customers_dict['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons **fusionner** ces deux DataFrames en utilisant la méthode **merge**. \n",
    "\n",
    "Nous spécifions la clé commune ***customer_id*** au sein du paramètre **on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(orders,customers, on='customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs choses sont à noter : \n",
    "\n",
    "- La méthode merge a supprimé l'index que nous avions créé\n",
    "- Une seule des deux colonnes a été utilisée\n",
    "- Le client qui n'était pas présent dans le DataFrame orders n'est pas présent dans le résultat final \n",
    "\n",
    "Par défaut, Pandas réalise une fusion dite **inner**.\n",
    "\n",
    "Il existe plusieurs de fusion entre deux sets de données. Les principales peuvent se résumer au sein du graphe ci-dessous : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/images/merge.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons spécifier à Pandas le type de fusion que nous souhaitons grâce au paramètre **how**. \n",
    "\n",
    "Si nous souhaitons par exemple réaliser une fusion à droite, nous écrirons : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(orders,customers,on='customer_id',how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le client James FRANKO, n'a ici pas de d'order_value associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de fusionner deux DataFrames, ne disposant pas des mêmes noms de colonnes, en utilisant les méthodes **left_on** et **right_on**. \n",
    "\n",
    "J'ajoute une colonne au sein du DataFrame orders : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['identifiant_client'] = orders['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si je souhaite réaliser une fusion sur la colonne **identifiant_client** pour mon DataFrame orders et sur customers, sur mon DataFrame customers, nous pouvons écrire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(orders,customers,left_on='identifiant_client',right_on='customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous notez dans ce cas, que les deux colonnes **customer_id** ont été renommées, en **customer_id_x** et **customer_id_y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas permet de retravailler des données tabulaires pour mieux les exploiter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reshaping intervient souvent après une opération de grouping sur plusieurs clés. \n",
    "\n",
    "Prenons le cas du dataset ***coffee_shop*** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv(\"data/coffee_shop.csv\")\n",
    "\n",
    "coffee.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous souhaitons connaître le nombre de ventes par **Market** et **Market Size**, nous écrirons : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_market = coffee['Sales'].groupby([coffee['Market'],coffee['Market Size']]).sum()\n",
    "\n",
    "coffee_market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coffee_market** est une Série dispose d'un **MultiIndex**. **Market** et **Market Size** sont deux index hiérarchisés, cf :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_market.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs choses sont à noter pour cet Index : \n",
    "\n",
    "- Nous avons deux **levels** ou **niveaux**, hiérarchisés\n",
    "- Ces **levels** disposent de noms (Market et Market Size), permettant de les appeler\n",
    "- Pandas a également ajouté des valeurs d'indice, appelé **labels**\n",
    "\n",
    "Les méthodes **stack** et **unstack** permettent de faire pivoter ces indices de lignes à colonnes, ou de colonnes à lignes :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_unstacked = coffee_market.unstack()\n",
    "coffee_unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode stack réalise l'inverse de la méthode **unstack** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_unstacked.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, les méthodes stack et unstack utilisent le **level** le plus bas pour réaliser un pivot (ici il s'agit de Market Size). \n",
    "                                                                                                  \n",
    "Nous pouvons toutefois spécifier le **level**, en utilisant le nom ou la position du **level** dans l'Index. \n",
    "\n",
    "Le level **Market** étant en première position, la rotation de lignes à colonnes sur le level **Market** peut s'écrire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_market.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ou encore : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_market.unstack('Market')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il arrive que les données soient stockées au format **stacked** au sein de bases de données. \n",
    "\n",
    "On souhaite dans ce cas réaliser la même rotation mais à partir d'une colonne (et non d'Index). \n",
    "\n",
    "Prenons le set **datalong.csv** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/datalong.csv\")\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas, nous disposons de trois 'items' : realgdp, infl et unemp. \n",
    "\n",
    "La ligne date est répétée autant de fois qu'il y a d'items distincts. \n",
    "\n",
    "Si nous souhaitons faire une rotation, en créant trois nouvelles colonnes, correspondant à chacune des valeurs de items, nous pouvons utiliser la méthode **pivot** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivoted = data.pivot('date','item')\n",
    "\n",
    "data_pivoted.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode **pivot** prend au moins deux arguments. Le premier est l'Index à utiliser pour les lignes, Le second est l'index à utiliser pour les colonnes. \n",
    "\n",
    "Le troisième paramètre est optionnel. Il permet de déterminer quelle valeur à utiliser pour remplir le DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons voir dans cette partie comment supprimer des doublons ou transformer des données à partir d'un dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les doublons sont omniprésents dans une analyse de données, la méthode **duplicate** permet de rapidement repérer et supprimer des doublons. Considérons le DataFrame suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons_dict = {'col1':['a','b','a','b','b','a'],\n",
    "            'col2':[1,1,1,2,2,3]}\n",
    "\n",
    "doublons = pd.DataFrame(doublons_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode **duplicated** permet de renvoyer un booléenn spécifiant si chacune des lignes est un doublon ou non :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, la méthode **duplicated** se base sur l'ensemble des colonnes du dataset. \n",
    "\n",
    "Nous pouvons spécifier la colonne à considérer en paramètre, soit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons.duplicated('col1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode **drop_duplicates** permet par ailleurs de supprimer directement toutes les lignes en doublon : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons.drop_duplicates('col1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformation de données passe également souvent par un mapping de valeurs avec un dictionnaire. \n",
    "\n",
    "Supposons que nous ayons un dictionnaire villes_customers qui associe à chaque customer_id, la ville de résidence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villes_customers = {'1':'Paris','2':'Seattle','3':'San Francisco','4':'Cupertino','5':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons réaliser un **mapping** de la colonne customer_id du DataFrame customers grâce à la fonction **map** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['customer_id'].map(villes_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A vous : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler dans cet exercice sur le set de données **Movielens** - https://movielens.org/. \n",
    "    \n",
    "Movielens est issu d'un groupe de recherche en Machine Learning de l'Université du Minnesota. Le service permet à un utilisateur de disposer de recommandations de films.\n",
    "\n",
    "Le set de données contient 1M+ d'avis, que 6k+ utilisateurs de Movielens ont donné sur 4k films depuis 2000. Trois fichiers sont disponibles : \n",
    "\n",
    "- **movies.dat** : MovieID::Title::Genres\n",
    "- **users.dat** : UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "    Les correspondances pour les âges sont : \n",
    "    \n",
    "    *  1:  \"Under 18\"\n",
    "\t* 18:  \"18-24\"\n",
    "\t* 25:  \"25-34\"\n",
    "\t* 35:  \"35-44\"\n",
    "\t* 45:  \"45-49\"\n",
    "\t* 50:  \"50-55\"\n",
    "\t* 56:  \"56+\"\n",
    "    \n",
    "    Les correspondances pour les occupations sont : \n",
    "    \n",
    "    *  0:  \"other\" or not specified\n",
    "\t*  1:  \"academic/educator\"\n",
    "\t*  2:  \"artist\"\n",
    "\t*  3:  \"clerical/admin\"\n",
    "\t*  4:  \"college/grad student\"\n",
    "\t*  5:  \"customer service\"\n",
    "\t*  6:  \"doctor/health care\"\n",
    "\t*  7:  \"executive/managerial\"\n",
    "\t*  8:  \"farmer\"\n",
    "\t*  9:  \"homemaker\"\n",
    "\t* 10:  \"K-12 student\"\n",
    "\t* 11:  \"lawyer\"\n",
    "\t* 12:  \"programmer\"\n",
    "\t* 13:  \"retired\"\n",
    "\t* 14:  \"sales/marketing\"\n",
    "\t* 15:  \"scientist\"\n",
    "\t* 16:  \"self-employed\"\n",
    "\t* 17:  \"technician/engineer\"\n",
    "\t* 18:  \"tradesman/craftsman\"\n",
    "\t* 19:  \"unemployed\"\n",
    "\t* 20:  \"writer\"\n",
    "    \n",
    "- **ratings.dat** : UserID::MovieID::Rating::Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons trois DataFrames : users, ratings et movies : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_table('data/movielens/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_table('data/movielens/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'genre']\n",
    "movies = pd.read_table('data/movielens/movies.dat', sep='::', names=m_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Créez un DataFrame unique en fusionnant les users, ratings et movies\n",
    "- Quels sont les 5 films qui ont été le plus noté ? \n",
    "- Quels sont les 5 films qui ont la meilleure note moyenne ayant été noté plus de 100 fois ? \n",
    "- Quelle est la tranche d'âge notant le moins bien ? \n",
    "- Les hommes notent ils moins bien que les femmes ? \n",
    "- [Avancé] Quels sont les films ayant la plus grande différence de notes entre les hommes et les femmes ? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
