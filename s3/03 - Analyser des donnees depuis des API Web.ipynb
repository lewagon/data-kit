{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyser des données depuis des API Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python permet de s'interfacer avec de nombreux services web (API). \n",
    "\n",
    "Dans cette partie nous verrons : \n",
    "\n",
    "- Ce qu'est une API \n",
    "- Comment Python et Pandas permettent de transformer des données brutes en un DataFrame exploitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction aux API Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une API (Application Programming Interface) permet de récupérer des des données mises à disposition par des services Web accessibles depuis une adresse particulière. \n",
    "\n",
    "La plupart des services Web (Google Analytics, Mixpanel, Twitter, Facebook, le New York Times etc..) dispose d'API ce qui en fait une source de données de choix. \n",
    "\n",
    "Python et Pandas sont d'excellents outils pour récupérer, transformer et analyser ces données web. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une URL (Unique Ressource Locator) permet d'identifier de manière unique une ressource sur Internet. Prenons l'URL suivante : "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "http://www.example.com/foo/bar?arg1=baz&arg2=quux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette URL se décompose en blocs logiques : \n",
    "\n",
    "- ***http://*** = le schéma, détermine le protocole que nous utilisons pour communiquer avec le service Web. Nous utiliserons principalement le protocole **http**\n",
    "- ***www.example.com*** = l'hôte qui détermine sur quel serveur de l'internet nous allons communiquer\n",
    "- ***/foo/bar*** = spécifie le chemin où se trouve la ressource\n",
    "- ***?arg1=baz&arg2=quux*** les paramètres de la requête"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML vs JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML permet de renvoyer de la donnée pour un utilisateur. Lorsqu'une requête est faite sur un serveur, celui-ci renvoie des éléments (html, css,js, etc..) permettant au navigateur d'afficher une page web **user-friendly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/images/html.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JSON permet de renvoyer de la donnée structurée, exploitable par une machine. Lorsqu'un service doit communiquer avec un autre service, les données renvoyées sont **machine-friendly**. Plusieurs formats sont possibles (CSV, JSON, XML etc..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/images/json.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le format JSON (Javascript Object Notation) est un des formats préférés des Web API. \n",
    "\n",
    "Il peut être composé de deux structures : \n",
    "\n",
    "- Dictionnaire clé / valeur\n",
    "- Tableaux d'objets \n",
    "\n",
    "Voici un exemple de JSON : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "     \"firstName\": \"John\",\n",
    "     \"lastName\": \"Smith\",\n",
    "     \"address\": {\n",
    "         \"streetAddress\": \"21 2nd Street\",\n",
    "         \"city\": \"New York\",\n",
    "         \"state\": \"NY\",\n",
    "         \"postalCode\": 10021\n",
    "     },\n",
    "     \"phoneNumbers\": [\n",
    "         \"212 555-1234\",\n",
    "         \"646 555-4567\"\n",
    "     ]\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples d'API populaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des services Web disposent d'API. Elles sont également documentées voici quelques exemples : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facebook - https://developers.facebook.com/tools/explorer/\n",
    "- Twitter - https://dev.twitter.com/rest/tools/console\n",
    "- Google Analytics - https://ga-dev-tools.appspot.com/explorer/\n",
    "- The New York Times - http://developer.nytimes.com/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it ! Analyse des tweets du compte officiel de l'Elysée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec près de 500 millions de tweets émis chaque jour, Twitter est une source de données inépuisable. \n",
    "\n",
    "Les données sont accessibles au format JSON par une API bien documentée. \n",
    "\n",
    "L'analyse des tweets offre plusieurs possibilités : \n",
    "\n",
    "- Analyse temporelle (date et heure d'émission)\n",
    "- Analyse texte, de sentiment\n",
    "- Analyse du nombre de retweets\n",
    "- Analyse de graphe (réponse, mentions etc..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, nous allons faire une analyse descriptive du compte Twitter officiel de l'Elysée (https://twitter.com/Elysee). \n",
    "\n",
    "Nous allons essayer de répondre à plusieurs questions : \n",
    "\n",
    "- Comment évolue le nombre de tweets sur le compte officiel ? \n",
    "- Y a t il des pics de retweets ? Si oui pourquoi ? \n",
    "- Quel sont les comptes que l'Elysée mentionne le plus ? \n",
    "- Quels sont les thèmes / hashtags les plus populaires ? \n",
    "- Comment ces thèmes évoluent ils dans le temps ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se connecter à l'API de Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreuses librairies Python ont été développées pour \"dialoguer\" avec l'API de Twitter. \n",
    "\n",
    "Une liste officielle des librairies Twitter par langage peut être trouvée à cette adresse - https://dev.twitter.com/overview/api/twitter-libraries\n",
    "    \n",
    "Pour les besoins de cet exercice, nous utiliserons la librairie **TwitterSearch** - https://github.com/ckoepp/TwitterSearch. Une documentation exhaustive des méthodes de cette librairie est disponible à l'adresse - https://twittersearch.readthedocs.org/en/latest/TwitterSearch.html\n",
    "\n",
    "Installez TwitterSearch depuis votre terminal en exécutant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install TwitterSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accès à l'API est sécurisé. Pour obtenir des clés d'accès : \n",
    "\n",
    "- Créez un compte Twitter\n",
    "- Créez une application sur https://apps.twitter.com/\n",
    "\n",
    "On peut dès lors appeler la librarie TwitterSearch en spécifiant ses identifiants de connexion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "twitter_api = TwitterSearch(\n",
    "    consumer_key = '¨* ',\n",
    "    consumer_secret = '*',\n",
    "    access_token = '*',\n",
    "    access_token_secret = '*'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons faire un premier test, en recherchant tous les tweets qui contiennent un mot en particulier. Nous utilisons pour cela la méthode **search_tweets** de l'objet **TwitterSearchOrder()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tso = TwitterSearchOrder() # nous créons ici un objet TwitterSearchOrder()\n",
    "tso.set_keywords(['Elysee']) # recherchons tous les tweets comportant le mot Elysee\n",
    "        \n",
    "search_results = twitter_api.search_tweets(tso) # La méthode search_tweets permet de rechercher tous les tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La réponse de l'API est au format JSON. Nous pouvons explorer le contenu, en utilisant la méthode **keys()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_results.keys())\n",
    "\n",
    "print(search_results['content'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(search_results['content']['statuses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet'statuses' est une liste de 100 éléments.\n",
    "\n",
    "Nous pouvons également afficher les clés de chacun des tweets renvoyés : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_results['content']['statuses'][99]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger et inspecter les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous souhaitons analyser l'intégralité des tweets d'un compte en particulier, nous devons utiliser l'objet **TwitterUserOrder** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuo = TwitterUserOrder('Elysee')\n",
    "\n",
    "elysee_results = twitter_api.search_tweets(tuo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons afficher le premier tweet renvoyé par notre requête via : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elysee_results['content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut donc réaliser une **boucle**. Le temps pour récupérer les données pouvant être long, on pourra utiliser le fichier **elysee.txt** qui contient un export des tweets bruts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    tuo = TwitterUserOrder('Elysee') \n",
    "\n",
    "    twitter_api = TwitterSearch(\n",
    "        consumer_key = 'XXX',\n",
    "        consumer_secret = 'XXX',\n",
    "        access_token = 'XXX',\n",
    "        access_token_secret = 'XXX'\n",
    "    )\n",
    "    \n",
    "    # perform search with iterables\n",
    "    for tweet in twitter_api.search_tweets_iterable(tuo):\n",
    "        data.append(tweet)\n",
    "\n",
    "except TwitterSearchException as e: # catch errors\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut importer le fichier **elysee.txt**, au format JSON qui contient l'ensemble des tweets de la timeline 'Elysee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elysee = json.load(open('data/elysee.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons rapidement la taille ainsi que la structure des objets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichons la taille du fichier\n",
    "\n",
    "print(len(elysee))\n",
    "\n",
    "# Affichons les clés du premier élément\n",
    "\n",
    "print(elysee[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser l'évolution des tweets dans le temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous intéresser dans un premier temps aux colonnes **text, retweet_count, created_at**.\n",
    "\n",
    "Au moment de créer notre DataFrame, nous pouvons donc spécifier les colonnes à utiliser. \n",
    "\n",
    "Faire également attention aux Index. Nous allons travailler avec un set de données temporel, il advient de bien spécifier l'index que nous allons utiliser : Voir ***03 - Focus série temporelles avec Python***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous créons ici notre DataFrame\n",
    "\n",
    "colonnes = ['text','retweet_count','created_at']\n",
    "\n",
    "elysee_df = pd.DataFrame(elysee, \n",
    "                         columns=colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous transformons la colonne created_at en serie temporelle grâce à la méthode to_datetime\n",
    "\n",
    "date = pd.to_datetime(elysee_df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous remplaçons l'index de notre DataFrame elysee_df en utilisant la méthode set_index\n",
    "\n",
    "elysee_df = elysee_df.set_index(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elysee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant afficher le nombre de tweets par jours, en utilisant la méthode resample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_date = elysee_df['text'].resample('W').count()\n",
    "\n",
    "count_date.plot().set_title('Nombre de tweets du compte @Elysee par semaine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A vous : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Afficher un graphe de l'évolution du nombre de retweets par jour. \n",
    "- Que s'est il passé en Juin 2014 et en Janvier 2015 ? \n",
    "- Afficher les tweets de la journée du 6 juin. Quel est celui qui a eu le plus de retweets?     \n",
    "- Quels sont les heures les plus importantes en terme de retweets ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les mentions et les hashtags les plus populaires "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python permet également de manipuler facilement des chaines de texte grâce aux expressions régulières ***(voir Focus expression régulière dans ce dossier)*** \n",
    "\n",
    "Nous pouvons extraire plusieurs informations intéressantes comme : \n",
    "\n",
    "- Les mentions (précédés d'un '@')\n",
    "- Les hastags (précédés d'un '#') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous souhaitons extraire les mentions de la colonne texte, nous pouvons écrire : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elysee_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_mentions = \"@[A-Z0-9._%+-]+\"\n",
    "\n",
    "elysee_df['mentions'] = elysee_df['text'].str.findall(pattern_mentions, re.IGNORECASE).str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut dés lors compter le nombre de mentions en groupant par la colonne mentions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elysee_df.groupby('mentions').size().sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A vous :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Quelles sont les mentions les plus populaires ? \n",
    "   - Quels sont les hashtags les plus populaires ? \n",
    "   - Quels sont les hashtages les plus populaires, mentionnant @gouvernementFR ? \n",
    "   - Quelles sont les mentions les plus populaires, comportant le hashtag #DDay70 ?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
